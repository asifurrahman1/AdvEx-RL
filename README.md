# ğŸ§  Adversarial Behavioral Exploration for Safe Reinforcement Learning (AdvEx-RL)

This repository contains the official implementation of the paper:  
ğŸ“„ [Adversarial Behavioral Exploration for Safe Reinforcement Learning â€“ IJCAI 2023](https://www.ijcai.org/proceedings/2023/54)

AdvEx-RL introduces a novel adversarial training framework to improve safety and robustness in reinforcement learning by leveraging adversarial exploration and behavior shaping strategies. The framework supports both **MuJoCo** and **Safety Gym** environments and enables extensive evaluation against existing baselines.

---

## ğŸ“‚ Repository Structure
```
AdvEx-RL/
â”œâ”€â”€ AdvExRL_MuJoCo_code/
â”‚ â”œâ”€â”€ AdvEx_RL/ # Core AdvEx-RL agent implementation
â”‚ â”œâ”€â”€ AdvEx_RL_config/ # Configs for adversary, victim, and safety agents
â”‚ â”œâ”€â”€ AdvEx_RL_Trained_Models/ # Pretrained models
â”‚ â”œâ”€â”€ RecoveryRL/ # Baseline methods (7 policies)
â”‚ â”œâ”€â”€ Experimental_Data/ # Output of experiments
â”‚ â”œâ”€â”€ plot_scripts/ # Plotting scripts
â”‚ â”œâ”€â”€ env/ # Environment wrappers
â”‚ â”œâ”€â”€ config/ # Environment configs
â”‚ â””â”€â”€ *.py # Evaluation & training scripts
â”œâ”€â”€ AdvExRL_SafetyGym_code/
â”‚ â”œâ”€â”€ AdvExRL_safetygym/ # AdvEx-RL SafetyGym implementation
â”‚ â”œâ”€â”€ sac_agent/ # SAC adversary agent
â”‚ â”œâ”€â”€ cpo_torch/, pytorch_trpo/ # Baseline implementations
â”‚ â”œâ”€â”€ plot_scripts/
â”‚ â”œâ”€â”€ safety_gym_file_replace/ # Engine modifications for demo rollout
â”‚ â””â”€â”€ *.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```


---

## ğŸ“¦ Installation Instructions

### âœ… Requirements

- Python 3.9.7  
- GPU with CUDA (â‰¥ 2 GB VRAM recommended)  
- MuJoCo 2.0.2.13  
- RAM â‰¥ 4 GB  

### ğŸ”§ MuJoCo Setup

1. Download MuJoCo ROM: http://www.roboti.us/
2. Extract and export path:
```bash
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:[ROM-bin-Path]
```
Create and activate virtual environment:
```bash
python3 -m venv venv
source venv/bin/activate
```
Install MuJoCo and dependencies:
```bash
pip install mujoco-py==2.0.2.13
cd AdvExRL_MuJoCo_code
pip install -r requirements.txt
```
Download pretrained models:
- AdvEx-RL Models â†’ extract into AdvEx_RL_Trained_Models

- RecoveryRL Models â†’ extract into RecoveryRL/RecoveryRL_Model

### âš™ï¸ Safety Gym Setup
Install dependencies:
```bash
cd AdvExRL_SafetyGym_code
pip install -r requirements.txt
```
Install Safety Gym:

```bash
git clone https://github.com/openai/safety-gym
cd safety-gym
pip install -e .
```
Replace Safety Gym engine files:
```bash
cp ../AdvExRL_SafetyGym_code/safety_gym_file_replace/engine.py safety_gym/envs/
cp ../AdvExRL_SafetyGym_code/safety_gym_file_replace/world.py safety_gym/envs/
```
Download SafetyGym trained models â†’ extract into AdvExRL_SafetyGym_code/Trained_models

---

## ğŸš€ Experiments
All experiments can be reproduced using the pretrained models and the scripts in the repository.

### ğŸ”¬ Robustness Experiments
| ID | Experiment Type            | Script                                           | Environment Examples      |
| -- | -------------------------- | ------------------------------------------------ | ------------------------- |
| 1  | Random attack              | `test_random_atk_experiment.py`                  | maze, nav1, nav2          |
| 2  | AAA attack                 | `test_aaa_atk_experiment.py`                     | maze, nav1, nav2          |
| 3  | Random + changed dynamics  | `test_random_atk_experiment_changed_dynamics.py` | --env-change 5.0/10.0/... |
| 4  | AAA + changed dynamics     | `test_aaa_atk_experiment_changed_dynamics.py`    | same as above             |
| 5  | Ablation (Random)          | `test_ablation_random_atk.py`                    | maze, nav1, nav2          |
| 6  | Ablation (AAA)             | `test_ablation_aaa_atk.py`                       | maze, nav1, nav2          |
| 7  | Deadlock Detection         | `deadlock_detection_aaa.py`                      | maze, nav1, nav2          |
| 8  | Threshold Sensitivity      | `test_safety_threshold_sensitivity.py`           | maze, nav1, nav2          |
| 9  | Render Random Perturbation | `render_episode_with_random_atk.py`              | maze, nav1, nav2          |
| 10 | Render AAA Perturbation    | `render_episode_with_aaa_atk.py`                 | maze, nav1, nav2          |


### ğŸ§ª SafetyGym Experiments
| ID | Experiment Type | Script           | Envs                                     |
| -- | --------------- | ---------------- | ---------------------------------------- |
| 11 | Random attack   | `test_random.py` | Safexp-CarGoal1-v0, Safexp-CarButton1-v0 |
| 12 | AAA attack      | `test_aaa.py`    | same                                     |


### ğŸ‹ï¸â€â™‚ï¸ Train From Scratch
#### Train task agent:
```bash
python train_victim.py --configure-env [maze|nav1|nav2]
```
#### Train adversary:
```bash
python train_adv.py --configure-env [maze|nav1|nav2]
```
Make sure to configure paths inside AdvEx_RL_config to point to the above models.
#### Train AdvEx-RL safety agent:
```bash
python train_safety_policy.py --configure-env [maze|nav1|nav2]
```

---

## ğŸ“Š Rendered Demonstrations
AdvEx-RL agent under 100% adversarial attack
<img src="rendered_fig.gif" width="350" height="250"/>

SAC agent under 100% adversarial attack
<img src="SAC_rendered_fig.gif" width="350" height="250"/>

## ğŸ“„ License
This project is licensed under the MIT License â€“ see the LICENSE file for details.

## ğŸ‘¤ Author
Md Asifur Rahman
For questions, collaborations, or issues, feel free to open an issue or reach out directly.
